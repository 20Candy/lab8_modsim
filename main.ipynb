{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Laboratorio 8 - Servidores\n",
    "Stefano Aragoni, Carol Arevalo, Luis Diego Santos\n",
    "\n",
    "---------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suponga que usted está a cargo de definir la arquitectura a usar en el lanzamiento de su próxima aplicación web: C3 (sistema de contabilidad de la carreta contadora). La junta directiva le ha solicitado que encuentre el mejor servicio de hosting para el proyecto. Después de una investigación gigante, usted concluye que las mejores opciones se reducen a las siguientes dos:\n",
    "\n",
    "1. **Proveedor 1 - Mountain Mega Computing:** Tienen una infraestructura de servidor único, con mucha potencia de procesamiento. Ellos se enorgullecen al indicar que *su servidor Enterprise puede atender hasta 100 solicitudes por segundo*.\n",
    "\n",
    "2. **Proveedor 2 - Pizzita computing:** Tienen una infraestructura de múltiples servidores (en nube). Cada servidor es medianamente potente, y en su promoción indican que se paga únicamente la cantidad de servidores que su aplicación requiera. Luego de su análisis de esta oferta, usted infiere que cada servidor tiene a lo sumo una décima parte de la potencia del servidor promocionado por Mountain Mega Computing (*hasta 10 solicitudes por segundo*).\n",
    "\n",
    "\n",
    "Las pruebas de estrés iniciales, y las proyecciones calculadas para los primeros dos años luego del lanzamiento, indican que <font color=red>su aplicación jamás excederá los 2,400 solicitudes por minuto</font>. Una auditoría y análisis de benchmark a sistemas similares al suyo, indican que <font color=orange>las solicitudes deberían llegar como un proceso de Poisson</font>, y que <font color=green>el tiempo de servicio de cada solicitud (sin importar la arquitectura de servidor usada) es modelado adecuadamente por una variable aleatoria exponencial</font>.\n",
    "\n",
    "\n",
    "Mañana tiene que presentar su decisión final a la junta directiva del proyecto. Como no tiene tiempo para hacer una investigación a detalle con los clientes de cada proveedor, decide creer en su promoción y hacer una simulación para concluir cuál será la mejor opción.\n",
    "\n",
    "--------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simulación - Tasks\n",
    "\n",
    "1. Modele, simule y analice el comportamiento de ambos sistemas durante una hora de ejecución de C3, y para cada sistema responda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Proveedor 1 - Estadísticas:\n",
      "a. Solicitudes atendidas: 143945\n",
      "b. Tiempo ocupado: 1439.45\n",
      "c. Tiempo desocupado: 2160.55\n",
      "d. Tiempo total en cola: 475.9282526066765\n",
      "e. Tiempo promedio en cola: 0.0033063201403777586\n",
      "f. Promedio de solicitudes en cola por segundo: 39.984722222222224\n",
      "g. Momento de la salida de la última solicitud: 3600\n",
      "\n",
      "Proveedor 2 - Estadísticas:\n",
      "a. Solicitudes atendidas: 144000\n",
      "b. Tiempo ocupado: 14400.0\n",
      "c. Tiempo desocupado: 21600.0\n",
      "d. Tiempo total en cola: 15.959870971545136\n",
      "e. Tiempo promedio en cola: 0.00011083243730239678\n",
      "f. Promedio de solicitudes en cola por segundo: 40.0\n",
      "g. Momento de la salida de la última solicitud: 3600\n"
     ]
    }
   ],
   "source": [
    "import simpy\n",
    "import numpy as np\n",
    "\n",
    "# Parámetros de la simulación\n",
    "LAMBDA = 2400/60  # solicitudes por segundo\n",
    "MU = 100  # solicitudes por segundo que puede atender el servidor de Mountain Mega Computing\n",
    "TIME = 3600  # 1 hora\n",
    "\n",
    "def source(env, number, lambda_, server, service_time):\n",
    "    \"\"\"Genera solicitudes aleatoriamente\"\"\"\n",
    "    for i in range(int(number)):\n",
    "        c = request(env, 'Request%02d' % i, server, service_time)\n",
    "        env.process(c)\n",
    "        t = np.random.exponential(1.0/lambda_)\n",
    "        yield env.timeout(t)\n",
    "\n",
    "def request(env, name, server, service_time):\n",
    "    \"\"\"Una solicitud llega al servidor para ser atendida\"\"\"\n",
    "    arrive = env.now\n",
    "    with server.request() as req:\n",
    "        results = yield req\n",
    "\n",
    "        wait = env.now - arrive\n",
    "        yield env.timeout(service_time)\n",
    "        total_wait.append(wait)\n",
    "        total_service.append(service_time)\n",
    "        total_served.append(1)\n",
    "\n",
    "# Simulación para el Proveedor 1\n",
    "env1 = simpy.Environment()\n",
    "server1 = simpy.Resource(env1, capacity=1)\n",
    "total_wait, total_service, total_served = [], [], []\n",
    "env1.process(source(env1, TIME*LAMBDA, LAMBDA, server1, 1.0/MU))\n",
    "env1.run(until=TIME)\n",
    "\n",
    "# Recopilar estadísticas para Proveedor 1\n",
    "total_requests_1 = sum(total_served)\n",
    "total_wait_time_1 = sum(total_wait)\n",
    "total_service_time_1 = sum(total_service)\n",
    "idle_time_1 = TIME - total_service_time_1\n",
    "average_queue_1 = len(total_wait) / TIME\n",
    "\n",
    "print(\"\\nProveedor 1 - Estadísticas:\")\n",
    "print(f\"a. Solicitudes atendidas: {total_requests_1}\")\n",
    "print(f\"b. Tiempo ocupado: {total_service_time_1}\")\n",
    "print(f\"c. Tiempo desocupado: {idle_time_1}\")\n",
    "print(f\"d. Tiempo total en cola: {total_wait_time_1}\")\n",
    "print(f\"e. Tiempo promedio en cola: {total_wait_time_1 / total_requests_1}\")\n",
    "print(f\"f. Promedio de solicitudes en cola por segundo: {average_queue_1}\")\n",
    "print(f\"g. Momento de la salida de la última solicitud: {TIME}\")\n",
    "\n",
    "# Simulación para el Proveedor 2\n",
    "env2 = simpy.Environment()\n",
    "server2 = simpy.Resource(env2, capacity=10)\n",
    "total_wait, total_service, total_served = [], [], []\n",
    "env2.process(source(env2, TIME*LAMBDA, LAMBDA, server2, 10.0/MU)) # Decima parte de la potencia del servidor 1\n",
    "env2.run(until=TIME)\n",
    "\n",
    "# Recopilar estadísticas para Proveedor 2\n",
    "total_requests_2 = sum(total_served)\n",
    "total_wait_time_2 = sum(total_wait)\n",
    "total_service_time_2 = sum(total_service)\n",
    "idle_time_2 = TIME * 10 - total_service_time_2 # Para 10 servidores\n",
    "average_queue_2 = len(total_wait) / TIME\n",
    "\n",
    "print(\"\\nProveedor 2 - Estadísticas:\")\n",
    "print(f\"a. Solicitudes atendidas: {total_requests_2}\")\n",
    "print(f\"b. Tiempo ocupado: {total_service_time_2}\")\n",
    "print(f\"c. Tiempo desocupado: {idle_time_2}\")\n",
    "print(f\"d. Tiempo total en cola: {total_wait_time_2}\")\n",
    "print(f\"e. Tiempo promedio en cola: {total_wait_time_2 / total_requests_2}\")\n",
    "print(f\"f. Promedio de solicitudes en cola por segundo: {average_queue_2}\")\n",
    "print(f\"g. Momento de la salida de la última solicitud: {TIME}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------\n",
    "\n",
    "2. Determine empíricamente cuántos servidores se necesitaría “alquilar” en Pizzita computing para asegurar que siempre habrá al menos un servidor disponible para atender una solicitud dada (en otras palabras, una solicitud nunca tiene que esperar en cola)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para determinar empíricamente cuántos servidores se necesitan en Pizzita computing,  se realizarán múltiples simulaciones, cada una con un número incremental de servidores, hasta que lleguemos a un punto donde ninguna solicitud tiene que esperar en cola.\n",
    "\n",
    "Este código inicializará una simulación con un servidor y la aumentará gradualmente hasta que no haya tiempo de espera. Al final, imprimirá cuántos servidores se necesitan para que ninguna solicitud espere en cola"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Con 1 servidor(es), el tiempo promedio de espera es: 1349.8000 segundos\n",
      "Con 2 servidor(es), el tiempo promedio de espera es: 904.8892 segundos\n",
      "Con 3 servidor(es), el tiempo promedio de espera es: 447.9486 segundos\n",
      "Con 4 servidor(es), el tiempo promedio de espera es: 2.9021 segundos\n",
      "Con 5 servidor(es), el tiempo promedio de espera es: 0.0294 segundos\n",
      "Con 6 servidor(es), el tiempo promedio de espera es: 0.0077 segundos\n",
      "Con 7 servidor(es), el tiempo promedio de espera es: 0.0026 segundos\n",
      "Con 8 servidor(es), el tiempo promedio de espera es: 0.0010 segundos\n",
      "Con 9 servidor(es), el tiempo promedio de espera es: 0.0003 segundos\n",
      "Con 10 servidor(es), el tiempo promedio de espera es: 0.0001 segundos\n",
      "Con 11 servidor(es), el tiempo promedio de espera es: 0.0000 segundos\n",
      "\n",
      "Se requieren al menos 11 servidores en Pizzita computing para asegurar que una solicitud nunca espera en cola.\n"
     ]
    }
   ],
   "source": [
    "# Parámetros de la simulación\n",
    "LAMBDA = 2400/60  # solicitudes por segundo\n",
    "MU = 100  # solicitudes por segundo que puede atender el servidor de Mountain Mega Computing\n",
    "TIME = 3600  # 1 hora\n",
    "\n",
    "def source(env, number, lambda_, server, service_time):\n",
    "    \"\"\"Genera solicitudes aleatoriamente\"\"\"\n",
    "    for i in range(int(number)):\n",
    "        c = request(env, 'Request%02d' % i, server, service_time)\n",
    "        env.process(c)\n",
    "        t = np.random.exponential(1.0/lambda_)\n",
    "        yield env.timeout(t)\n",
    "\n",
    "def request(env, name, server, service_time):\n",
    "    \"\"\"Una solicitud llega al servidor para ser atendida\"\"\"\n",
    "    arrive = env.now\n",
    "    with server.request() as req:\n",
    "        results = yield req\n",
    "\n",
    "        wait = env.now - arrive\n",
    "        yield env.timeout(service_time)\n",
    "        total_wait.append(wait)\n",
    "        total_served.append(1)\n",
    "\n",
    "num_servers = 1\n",
    "while True:\n",
    "    env = simpy.Environment()\n",
    "    server = simpy.Resource(env, capacity=num_servers)\n",
    "    total_wait, total_served = [], []\n",
    "    env.process(source(env, TIME*LAMBDA, LAMBDA, server, 10.0/MU)) # 10.0/MU para Pizzita\n",
    "    env.run(until=TIME)\n",
    "\n",
    "    total_requests = sum(total_served)\n",
    "    total_wait_time = sum(total_wait)\n",
    "    average_wait_time = total_wait_time / total_requests if total_requests != 0 else 0\n",
    "\n",
    "    print(f\"Con {num_servers} servidor(es), el tiempo promedio de espera es: {average_wait_time:.4f} segundos\")\n",
    "\n",
    "    if average_wait_time < 1e-4:  # Aproximado a cero\n",
    "        print(f\"\\nSe requieren al menos {num_servers} servidores en Pizzita computing para asegurar que una solicitud nunca espera en cola.\")\n",
    "        break\n",
    "\n",
    "    num_servers += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------\n",
    "\n",
    "3. Se espera que a partir del tercer año del lanzamiento de su aplicación, la cantidad de usuarios sufra un alza, y por tanto deberán atender como máximo 6000 solicitudes por minuto. Resuelva el inciso 1 y 2 para esta nueva configuración."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Proveedor 1 - Estadísticas:\n",
      "a. Solicitudes atendidas: 359345\n",
      "b. Tiempo ocupado: 3593.4500000000003\n",
      "c. Tiempo desocupado: 6.549999999999727\n",
      "d. Tiempo total en cola: 1492625.8756564877\n",
      "e. Tiempo promedio en cola: 4.153740487989224\n",
      "f. Promedio de solicitudes en cola por segundo: 99.81805555555556\n",
      "g. Momento de la salida de la última solicitud: 3600\n",
      "\n",
      "Proveedor 2 - Estadísticas:\n",
      "a. Solicitudes atendidas: 359695\n",
      "b. Tiempo ocupado: 35969.5\n",
      "c. Tiempo desocupado: 30.5\n",
      "d. Tiempo total en cola: 973032.8274250136\n",
      "e. Tiempo promedio en cola: 2.7051608374456517\n",
      "f. Promedio de solicitudes en cola por segundo: 99.91527777777777\n",
      "g. Momento de la salida de la última solicitud: 3600\n"
     ]
    }
   ],
   "source": [
    "# Parámetros de la simulación\n",
    "LAMBDA = 6000/60  # solicitudes por segundo con el nuevo valor\n",
    "MU = 100  # solicitudes por segundo que puede atender el servidor de Mountain Mega Computing\n",
    "TIME = 3600  # 1 hora\n",
    "\n",
    "def source(env, number, lambda_, server, service_time):\n",
    "    \"\"\"Genera solicitudes aleatoriamente\"\"\"\n",
    "    for i in range(int(number)):\n",
    "        c = request(env, 'Request%02d' % i, server, service_time)\n",
    "        env.process(c)\n",
    "        t = np.random.exponential(1.0/lambda_)\n",
    "        yield env.timeout(t)\n",
    "\n",
    "def request(env, name, server, service_time):\n",
    "    \"\"\"Una solicitud llega al servidor para ser atendida\"\"\"\n",
    "    arrive = env.now\n",
    "    with server.request() as req:\n",
    "        results = yield req\n",
    "\n",
    "        wait = env.now - arrive\n",
    "        yield env.timeout(service_time)\n",
    "        total_wait.append(wait)\n",
    "        total_service.append(service_time)\n",
    "        total_served.append(1)\n",
    "\n",
    "# Simulación para el Proveedor 1\n",
    "env1 = simpy.Environment()\n",
    "server1 = simpy.Resource(env1, capacity=1)\n",
    "total_wait, total_service, total_served = [], [], []\n",
    "env1.process(source(env1, TIME*LAMBDA, LAMBDA, server1, 1.0/MU))\n",
    "env1.run(until=TIME)\n",
    "\n",
    "# Recopilar estadísticas para Proveedor 1\n",
    "total_requests_1 = sum(total_served)\n",
    "total_wait_time_1 = sum(total_wait)\n",
    "total_service_time_1 = sum(total_service)\n",
    "idle_time_1 = TIME - total_service_time_1\n",
    "average_queue_1 = len(total_wait) / TIME\n",
    "\n",
    "print(\"\\nProveedor 1 - Estadísticas:\")\n",
    "print(f\"a. Solicitudes atendidas: {total_requests_1}\")\n",
    "print(f\"b. Tiempo ocupado: {total_service_time_1}\")\n",
    "print(f\"c. Tiempo desocupado: {idle_time_1}\")\n",
    "print(f\"d. Tiempo total en cola: {total_wait_time_1}\")\n",
    "print(f\"e. Tiempo promedio en cola: {total_wait_time_1 / total_requests_1}\")\n",
    "print(f\"f. Promedio de solicitudes en cola por segundo: {average_queue_1}\")\n",
    "print(f\"g. Momento de la salida de la última solicitud: {TIME}\")\n",
    "\n",
    "# Simulación para el Proveedor 2\n",
    "env2 = simpy.Environment()\n",
    "server2 = simpy.Resource(env2, capacity=10)\n",
    "total_wait, total_service, total_served = [], [], []\n",
    "env2.process(source(env2, TIME*LAMBDA, LAMBDA, server2, 10.0/MU)) # Nota el 10.0/MU aquí\n",
    "env2.run(until=TIME)\n",
    "\n",
    "# Recopilar estadísticas para Proveedor 2\n",
    "total_requests_2 = sum(total_served)\n",
    "total_wait_time_2 = sum(total_wait)\n",
    "total_service_time_2 = sum(total_service)\n",
    "idle_time_2 = TIME * 10 - total_service_time_2 # Para 10 servidores\n",
    "average_queue_2 = len(total_wait) / TIME\n",
    "\n",
    "print(\"\\nProveedor 2 - Estadísticas:\")\n",
    "print(f\"a. Solicitudes atendidas: {total_requests_2}\")\n",
    "print(f\"b. Tiempo ocupado: {total_service_time_2}\")\n",
    "print(f\"c. Tiempo desocupado: {idle_time_2}\")\n",
    "print(f\"d. Tiempo total en cola: {total_wait_time_2}\")\n",
    "print(f\"e. Tiempo promedio en cola: {total_wait_time_2 / total_requests_2}\")\n",
    "print(f\"f. Promedio de solicitudes en cola por segundo: {average_queue_2}\")\n",
    "print(f\"g. Momento de la salida de la última solicitud: {TIME}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Con 1 servidor(es), el tiempo promedio de espera es: 1620.0081 segundos\n",
      "Con 2 servidor(es), el tiempo promedio de espera es: 1440.0367 segundos\n",
      "Con 3 servidor(es), el tiempo promedio de espera es: 1258.9771 segundos\n",
      "Con 4 servidor(es), el tiempo promedio de espera es: 1077.1893 segundos\n",
      "Con 5 servidor(es), el tiempo promedio de espera es: 900.0966 segundos\n",
      "Con 6 servidor(es), el tiempo promedio de espera es: 720.5146 segundos\n",
      "Con 7 servidor(es), el tiempo promedio de espera es: 540.2350 segundos\n",
      "Con 8 servidor(es), el tiempo promedio de espera es: 366.3134 segundos\n",
      "Con 9 servidor(es), el tiempo promedio de espera es: 179.7534 segundos\n",
      "Con 10 servidor(es), el tiempo promedio de espera es: 2.9225 segundos\n",
      "Con 11 servidor(es), el tiempo promedio de espera es: 0.0360 segundos\n",
      "Con 12 servidor(es), el tiempo promedio de espera es: 0.0121 segundos\n",
      "Con 13 servidor(es), el tiempo promedio de espera es: 0.0054 segundos\n",
      "Con 14 servidor(es), el tiempo promedio de espera es: 0.0026 segundos\n",
      "Con 15 servidor(es), el tiempo promedio de espera es: 0.0012 segundos\n",
      "Con 16 servidor(es), el tiempo promedio de espera es: 0.0006 segundos\n",
      "Con 17 servidor(es), el tiempo promedio de espera es: 0.0003 segundos\n",
      "Con 18 servidor(es), el tiempo promedio de espera es: 0.0002 segundos\n",
      "Con 19 servidor(es), el tiempo promedio de espera es: 0.0001 segundos\n",
      "\n",
      "Se requieren al menos 19 servidores en Pizzita computing para asegurar que una solicitud nunca espera en cola.\n"
     ]
    }
   ],
   "source": [
    "# Parámetros de la simulación\n",
    "LAMBDA = 6000/60  # solicitudes por segundo con el nuevo valor\n",
    "MU = 100  # solicitudes por segundo que puede atender el servidor de Mountain Mega Computing\n",
    "TIME = 3600  # 1 hora\n",
    "\n",
    "def source(env, number, lambda_, server, service_time):\n",
    "    \"\"\"Genera solicitudes aleatoriamente\"\"\"\n",
    "    for i in range(int(number)):\n",
    "        c = request(env, 'Request%02d' % i, server, service_time)\n",
    "        env.process(c)\n",
    "        t = np.random.exponential(1.0/lambda_)\n",
    "        yield env.timeout(t)\n",
    "\n",
    "def request(env, name, server, service_time):\n",
    "    \"\"\"Una solicitud llega al servidor para ser atendida\"\"\"\n",
    "    arrive = env.now\n",
    "    with server.request() as req:\n",
    "        results = yield req\n",
    "\n",
    "        wait = env.now - arrive\n",
    "        yield env.timeout(service_time)\n",
    "        total_wait.append(wait)\n",
    "        total_served.append(1)\n",
    "\n",
    "num_servers = 1\n",
    "while True:\n",
    "    env = simpy.Environment()\n",
    "    server = simpy.Resource(env, capacity=num_servers)\n",
    "    total_wait, total_served = [], []\n",
    "    env.process(source(env, TIME*LAMBDA, LAMBDA, server, 10.0/MU)) # 10.0/MU para Pizzita\n",
    "    env.run(until=TIME)\n",
    "\n",
    "    total_requests = sum(total_served)\n",
    "    total_wait_time = sum(total_wait)\n",
    "    average_wait_time = total_wait_time / total_requests if total_requests != 0 else 0\n",
    "\n",
    "    print(f\"Con {num_servers} servidor(es), el tiempo promedio de espera es: {average_wait_time:.4f} segundos\")\n",
    "\n",
    "    if average_wait_time < 1e-4:  # Aproximado a cero\n",
    "        print(f\"\\nSe requieren al menos {num_servers} servidores en Pizzita computing para asegurar que una solicitud nunca espera en cola.\")\n",
    "        break\n",
    "\n",
    "    num_servers += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------\n",
    "\n",
    "4. Emita una recomendación para la junta directiva"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Después de ejecutar simulaciones con la carga de trabajo esperada a partir del tercer año del lanzamiento de la aplicación (6000 solicitudes por minuto), se encontraron los siguientes resultados:\n",
    "\n",
    "**Proveedor 1 - Mountain Mega Computing**:\n",
    "- A pesar de tener un servidor con alta capacidad, no es suficiente para manejar la nueva carga de trabajo. Las solicitudes están esperando en cola un promedio de más de 4 segundos, lo que es bastante alto.\n",
    "- Aunque puede manejar un gran volumen de solicitudes, el sistema no es escalable.\n",
    "\n",
    "**Proveedor 2 - Pizzita Computing**:\n",
    "- Con 10 servidores (que es el número equivalente de capacidad al servidor de Mountain Mega Computing), todavía hay un tiempo de espera en cola, aunque es menor que el Proveedor 1.\n",
    "- Se determinó que para asegurar que una solicitud nunca tenga que esperar en cola, se necesitarían alquilar 19 servidores de Pizzita Computing. Esto indica escalabilidad en la infraestructura de Pizzita.\n",
    "\n",
    "**Recomendación**:\n",
    "\n",
    "A corto plazo (primeros dos años), el Proveedor 1 parece ser una opción más económica y eficiente. Sin embargo, con la expectativa de crecimiento en el tercer año, el Proveedor 1 no podrá manejar el volumen de tráfico sin tiempos de espera significativos.\n",
    "\n",
    "Por otro lado, Pizzita Computing, aunque inicialmente puede requerir una inversión en más servidores, ofrece escalabilidad. A medida que aumenta el tráfico, simplemente podemos añadir más servidores.\n",
    "\n",
    "Recomiendo que para los primeros dos años, si la diferencia de costos no es significativa, optemos por Pizzita Computing desde el principio. De esta manera, nos preparamos para el alza esperada en el tercer año y más allá, simplemente añadiendo más servidores a medida que se necesiten. Esto proporcionará una transición sin problemas, evitando cambios de infraestructura en el futuro y asegurando tiempos de respuesta rápidos para los usuarios.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
